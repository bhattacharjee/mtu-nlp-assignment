{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmentation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattacharjee/mtu-nlp-assignment/blob/main/assignment2/notebooks/Augmentation_wip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0639f409-2aa8-4eaf-ee0a-d7a8f6545e78",
        "id": "gwD52NTcePCl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 13.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 10.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 13.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 40.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 12.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 13.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 461 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 12.5 MB/s \n",
            "\u001b[?25h  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'mtu-nlp-assignment'...\n",
            "remote: Repository not found.\n",
            "fatal: Authentication failed for 'https://:@github.com/bhattacharjee/mtu-nlp-assignment.git/'\n",
            "Cloning into 'mtu-nlp-assignment'...\n",
            "remote: Enumerating objects: 1101, done.\u001b[K\n",
            "remote: Counting objects: 100% (1101/1101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (960/960), done.\u001b[K\n",
            "remote: Total 1101 (delta 562), reused 393 (delta 137), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 96.14 MiB | 24.15 MiB/s, done.\n",
            "Resolving deltas: 100% (562/562), done.\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "!pip install torchvision==0.8.2  -q -q -q\n",
        "!pip install torchtext==0.8.1    -q -q -q\n",
        "!pip install torchaudio==0.7.2   -q -q -q\n",
        "!pip install torch==1.7.1        -q -q -q\n",
        "!pip install tqdm==4.49.0        -q -q -q\n",
        "!pip install transformers==4.2.2 -q -q -q\n",
        "!pip install tensorflow          -q -q -q\n",
        "!pip install tensorboard         -q -q -q\n",
        "!pip install tensorboardX        -q -q -q\n",
        "!pip install --upgrade virtualenv -q -q -q\n",
        "!pip install sentencepiece==0.1.94       -q -q -q\n",
        "!pip install mosestokenizer==1.1.0 -q -q -q\n",
        "\n",
        "!USERNAME=bhattacharjee PASSWORD=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 git clone \"https://${USERNAME}:${PASSWORD}@github.com/bhattacharjee/mtu-nlp-assignment.git\"\n",
        "!rm -rf mtu-nlp-assignment\n",
        "!git clone https://bhattacharjee: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@github.com/bhattacharjee/mtu-nlp-assignment.git\n",
        "!cp mtu-nlp-assignment/work/augment_data/convert_to_squad.py .\n",
        "!cp mtu-nlp-assignment/work/augment_data/util.py .\n",
        "!cp mtu-nlp-assignment/work/augment_data/args.py .\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile copy_train.sh\n",
        "#!/bin/bash\n",
        "cp /content/gdrive/MyDrive/NLP/NLP-Save-Train/train.tar.gz /tmp\n",
        "cd /tmp\n",
        "gunzip train.tar.gz\n",
        "tar -xf train.tar\n",
        "ls /tmp/train"
      ],
      "metadata": {
        "id": "tXDJM3pMquXd",
        "outputId": "49dcb5ae-b201-4b14-b046-7e000aaf8c96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing copy_train.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/bin/bash copy_train.sh"
      ],
      "metadata": {
        "id": "XRjVoCQzqysT",
        "outputId": "93b9dac7-5245-4780-9184-92ffb8593e69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_mask\tid\t   offset_mapping\t       start_positions\n",
            "end_positions\tinput_ids  overflow_to_sample_mapping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip mtu-nlp-assignment/assignment2/robustqa.zip\n",
        "!mv robustqa/datasets_50k.tar.gz datasets_50k.tar\n",
        "!tar -xf datasets_50k.tar"
      ],
      "metadata": {
        "id": "MLkhLTlbst0N",
        "outputId": "0eff91bb-8d4f-4767-b617-1ebf7f72cb14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mtu-nlp-assignment/assignment2/robustqa.zip\n",
            "   creating: robustqa/\n",
            "  inflating: robustqa/datasets_50k.tar.gz  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/robustqa/\n",
            "  inflating: __MACOSX/robustqa/._datasets_50k.tar.gz  \n",
            "  inflating: robustqa/convert_to_squad.py  \n",
            "  inflating: robustqa/environment.yml  \n",
            "  inflating: robustqa/util.py        \n",
            "  inflating: robustqa/README.md      \n",
            "  inflating: __MACOSX/robustqa/._README.md  \n",
            "  inflating: robustqa/train.py       \n",
            "  inflating: robustqa/args.py        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BackTranslation Implementation"
      ],
      "metadata": {
        "id": "VOLlEKN8eZ3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using cuda\")\n",
        "    torch_device = 'cuda'\n",
        "    cuda = torch.device('cuda')\n",
        "    print(cuda)\n",
        "    #torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    torch_device = 'cpu'\n",
        "\n",
        "target_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
        "target_tokenizer = MarianTokenizer.from_pretrained(target_model_name)\n",
        "target_model = MarianMTModel.from_pretrained(target_model_name)\n",
        "\n",
        "en_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
        "en_tokenizer = MarianTokenizer.from_pretrained(en_model_name)\n",
        "en_model = MarianMTModel.from_pretrained(en_model_name)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    target_model = target_model.to(torch_device)\n",
        "    en_model = en_model.to(torch_device)\n",
        "\n",
        "import gc\n",
        "def translate(textarray, model, tokenizer, lang=\"fr\"):\n",
        "    # Prepare the text data into appropriate format for the model\n",
        "    try:\n",
        "        model.eval()\n",
        "    except:\n",
        "        print(f\"Model has no method called eval lang={lang}\")\n",
        "        pass\n",
        "    with torch.no_grad():\n",
        "        def templatize(text):\n",
        "            if lang== 'en':\n",
        "                # We're ending up with circular references somehow\n",
        "                # and that is leaking GPU memory\n",
        "                # Duplicating a string before translation\n",
        "                return \"\".join(list(text))\n",
        "            else:\n",
        "                return f\">>{lang}<< {text}\"\n",
        "        textarray = [templatize(t) for t in textarray]\n",
        "        encoded = tokenizer.prepare_seq2seq_batch(textarray, return_tensors='pt').to(torch_device)\n",
        "        #translated = model.generate(**encoded).to(torch_device)\n",
        "        translated = model.generate(**encoded)\n",
        "        translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "        encoded = encoded.to('cpu')\n",
        "        translated = translated.to('cpu')\n",
        "        del encoded\n",
        "        del translated\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        return [str(t) for t in translated_texts]\n",
        "\n",
        "def back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n",
        "    # Translate from source to target language\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    fr_texts = translate(texts, target_model, target_tokenizer, \n",
        "                         lang=target_lang)\n",
        "    # Translate from target language back to source language\n",
        "    back_translated_texts = translate(fr_texts, en_model, en_tokenizer, \n",
        "                                      lang=source_lang)\n",
        "    return back_translated_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08e48e3-77ea-47b7-804d-7534a29800a4",
        "id": "uWVUx0bueTI2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read squad and translate"
      ],
      "metadata": {
        "id": "ktHHWQhglvf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/usr/bin/env python3\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import csv\n",
        "import util\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "from transformers import AdamW\n",
        "from args import *\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
        "from args import get_train_test_args\n",
        "\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "def get_dataset(args, datasets, data_dir, tokenizer, split_name):\n",
        "    datasets = datasets.split(',')\n",
        "    dataset_dict = None\n",
        "    dataset_name=''\n",
        "    for dataset in datasets:\n",
        "        dataset_name += f'_{dataset}'\n",
        "        dataset_dict_curr = util.read_squad(f'{data_dir}/{dataset}')\n",
        "        dataset_dict = util.merge(dataset_dict, dataset_dict_curr)\n",
        "    return dataset_dict\n",
        "\n",
        "def print_question(question, context, ind, answer):\n",
        "    print(f\"ID:            {ind}\")\n",
        "    print(f\"CONTEXT:       {context}\")\n",
        "    print(f\"QUESTOIN:      {context}\")\n",
        "    print(f\"ANSWER:        {answer}\")\n",
        "    anslen = len(ans)\n",
        "\n",
        "def get_new_context(context:str, answer:str)->tuple:\n",
        "    \"\"\"\n",
        "    Replace the answer in the context with a number\n",
        "    so that it doesn't backtranslate\n",
        "\n",
        "    Return a tuple:\n",
        "        1. string that was replaced, handy while restoring\n",
        "           the answer in the translated string\n",
        "        2. translated question\n",
        "    \"\"\"\n",
        "    replaced_str = \"\"\n",
        "    start_ind = context.index(answer)\n",
        "    orig_ans = answer\n",
        "    len_orig_ans = len(orig_ans)\n",
        "    context = list(context)\n",
        "\n",
        "    for i in range(len_orig_ans):\n",
        "        replaced_str +=  '1'\n",
        "        context[i + start_ind] = '1'\n",
        "\n",
        "    print('-' * 80)\n",
        "    print(replaced_str)\n",
        "    print('-' * 80)\n",
        "    return \"\".join(context), replaced_str\n",
        "\n",
        "def get_start_end_index(context, replaced):\n",
        "    with open(\"save.txt\", \"a\") as f:\n",
        "        print(context, file=f)\n",
        "        print(replaced, file=f)\n",
        "\n",
        "    try:\n",
        "        start_ind = context.index(replaced)\n",
        "    except:\n",
        "        # Sometimes the replaced string is truncated by the\n",
        "        # translation, try again with half the string to see\n",
        "        # if there is a match\n",
        "        if len(replaced) < 4:\n",
        "            return -1, -1\n",
        "        try:\n",
        "            start_ind = context.index(replaced[:len(replaced) // 2])\n",
        "        except:\n",
        "            if len(replaced) < 8:\n",
        "                return -1, -1\n",
        "            try:\n",
        "                start_ind = context.index(replaced[len(replaced) // 4])\n",
        "            except:\n",
        "                return -1, -1\n",
        "\n",
        "    start_char = replaced[0]\n",
        "    end_ind = start_ind\n",
        "    while end_ind < len(context) and context[end_ind] == start_char:\n",
        "        end_ind += 1\n",
        "    return start_ind, end_ind\n",
        "\n",
        "\n",
        "    \n",
        "def reconstruct_context(context:str, replaced:str, origans:str)->str:\n",
        "    \"\"\"\n",
        "    Take the backtranslated context, and replace the placeholder\n",
        "    for the answer with the actual answer\n",
        "    \"\"\"\n",
        "    start_index, end_index = get_start_end_index(context, replaced)\n",
        "    str1 = context[:start_index]\n",
        "    str2 = context[end_index:]\n",
        "    return str1 + origans + str2\n",
        "\n",
        "def back_translate_context(context, answer):\n",
        "    temp_ctx, replaced = get_new_context(context, answer)\n",
        "    trns_ctx = back_translate(temp_ctx)[0]\n",
        "    new_ctx = reconstruct_context(trns_ctx, replaced, answer)\n",
        "    return new_ctx\n",
        "\n",
        "\"\"\"\n",
        "def main():\n",
        "    # define parser and arguments\n",
        "    import sys\n",
        "    sys.argv = ['']\n",
        "    args = get_train_test_args()\n",
        "\n",
        "    util.set_seed(args.seed)\n",
        "    print(args)\n",
        "\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "    args.save_dir = util.get_save_dir(args.save_dir, args.run_name)\n",
        "    log = util.get_logger(args.save_dir, 'log_train')\n",
        "    train_dataset = get_dataset(args, args.train_datasets, args.train_dir, None, 'train')\n",
        "\n",
        "    print(train_dataset.keys())\n",
        "\n",
        "    forig = open(\"orig.txt\", \"w\")\n",
        "    fnew = open(\"new.txt\", \"w\")\n",
        "\n",
        "    questions = train_dataset['question']\n",
        "    contexts = train_dataset['context']\n",
        "    ids = train_dataset['id']\n",
        "    answers = train_dataset['answer']\n",
        "    j = 0\n",
        "    for q, c, i, a in zip(questions, contexts, ids, answers):\n",
        "        if j == 4:\n",
        "            answer = a['text'][0]\n",
        "            nc = back_translate_context(c, answer)\n",
        "            nq = back_translate(q)\n",
        "\n",
        "            print(c, file=forig)\n",
        "            print(q, file=forig)\n",
        "            print(answer, file=forig)\n",
        "            print(\"\", file=forig)\n",
        "\n",
        "            print(nc, file=fnew)\n",
        "            print(nq, file=fnew)\n",
        "            print(answer, file=fnew)\n",
        "            print(\"\", file=fnew)\n",
        "\n",
        "        j += 1\n",
        "        if j > 10: break\n",
        "\n",
        "    forig.close()\n",
        "    fnew.close()\n",
        "\n",
        "\n",
        "main()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fvfeN9ukg8Vr",
        "outputId": "bdc02af0-1c58-4946-875b-94ea9d78072a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef main():\\n    # define parser and arguments\\n    import sys\\n    sys.argv = [\\'\\']\\n    args = get_train_test_args()\\n\\n    util.set_seed(args.seed)\\n    print(args)\\n\\n    if not os.path.exists(args.save_dir):\\n        os.makedirs(args.save_dir)\\n    args.save_dir = util.get_save_dir(args.save_dir, args.run_name)\\n    log = util.get_logger(args.save_dir, \\'log_train\\')\\n    train_dataset = get_dataset(args, args.train_datasets, args.train_dir, None, \\'train\\')\\n\\n    print(train_dataset.keys())\\n\\n    forig = open(\"orig.txt\", \"w\")\\n    fnew = open(\"new.txt\", \"w\")\\n\\n    questions = train_dataset[\\'question\\']\\n    contexts = train_dataset[\\'context\\']\\n    ids = train_dataset[\\'id\\']\\n    answers = train_dataset[\\'answer\\']\\n    j = 0\\n    for q, c, i, a in zip(questions, contexts, ids, answers):\\n        if j == 4:\\n            answer = a[\\'text\\'][0]\\n            nc = back_translate_context(c, answer)\\n            nq = back_translate(q)\\n\\n            print(c, file=forig)\\n            print(q, file=forig)\\n            print(answer, file=forig)\\n            print(\"\", file=forig)\\n\\n            print(nc, file=fnew)\\n            print(nq, file=fnew)\\n            print(answer, file=fnew)\\n            print(\"\", file=fnew)\\n\\n        j += 1\\n        if j > 10: break\\n\\n    forig.close()\\n    fnew.close()\\n\\n\\nmain()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the dataset"
      ],
      "metadata": {
        "id": "fy9GNEdweXtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/usr/bin/env python3\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import csv\n",
        "import util\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "from transformers import AdamW\n",
        "from args import *\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
        "from args import get_train_test_args\n",
        "\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import sys\n",
        "sys.argv = ['']\n",
        "args = get_train_test_args()\n",
        "util.set_seed(args.seed)\n",
        "dataset = get_dataset(args, args.train_datasets, args.train_dir, None, 'train')\n",
        "print([str(k) for k in dataset.keys()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it1z6ONNbO7x",
        "outputId": "19ea746c-e1ed-4552-b2e4-b0cbc1a7faa5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['question', 'context', 'id', 'answer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reformat to use map()\n",
        "Since we want to use map, reformat to make each example one item in the array"
      ],
      "metadata": {
        "id": "ibodx3RueN-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for ind in range(len(dataset['id'])):\n",
        "    innerdict = dict()\n",
        "    innerdict['question'] = dataset['question'][ind]\n",
        "    innerdict['context'] = dataset['context'][ind]\n",
        "    innerdict['id'] = dataset['id'][ind]\n",
        "    innerdict['answer_start'] = dataset['answer'][ind]['answer_start'][0]\n",
        "    innerdict['answer_text'] = dataset['answer'][ind]['text'][0]\n",
        "\n",
        "    data.append(innerdict)"
      ],
      "metadata": {
        "id": "CwSjtYj7clFP"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NewField: intermediate_context, orig_answer_len\n",
        "- intermediate_context : Original context with the answer replaced with 1111..\n",
        "- orig_answer_len : Length of the original answer"
      ],
      "metadata": {
        "id": "M8F9UXlrnFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_new_context(thedict:dict)->dict:\n",
        "    \"\"\"\n",
        "    Adds two new fields:\n",
        "    intermediate_context: The old context with the answer replaced with 1111s\n",
        "    orig_ansewr_len: The length of the original answer\n",
        "    \"\"\"\n",
        "    context         = thedict['context']\n",
        "    answer          = thedict['answer_text']\n",
        "    ans_start_ind   = context.index(answer)\n",
        "    orig_answer_len = len(answer)\n",
        "\n",
        "    context = list(context)\n",
        "    replaced_string = \"\"\n",
        "    for i in range(orig_answer_len):\n",
        "        replaced_string += '1'\n",
        "        context[i + ans_start_ind] = '1'\n",
        "    new_context = \"\".join(context)\n",
        "\n",
        "\n",
        "    out_dict = {k: v for k, v in thedict.items()}\n",
        "    out_dict['intermediate_context'] = new_context\n",
        "    out_dict['orig_answer_len'] = orig_answer_len\n",
        "    out_dict['replaced_string'] = replaced_string\n",
        "\n",
        "\n",
        "    return out_dict\n",
        "\n",
        "def get_new_id(thedict:dict)->dict:\n",
        "    \"\"\"\n",
        "    We need a new ID as this is augmented data and the ids should not\n",
        "    clash with the original data\n",
        "    \"\"\"\n",
        "    out_dict = {k: v for k, v in thedict.items()}\n",
        "    out_dict['id'] = 'deadcafe' + thedict['id']\n",
        "    return out_dict\n",
        "\n",
        "data2 = map(get_new_context, data)\n",
        "data2 = map(get_new_id, data2)\n",
        "data2 = list(data2)"
      ],
      "metadata": {
        "id": "y5KianxCd0UU"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### NewField: translated_question\n",
        " - translated_question : The original question after backtranslation"
      ],
      "metadata": {
        "id": "1LVZwd-anb76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backtranslate_questions_only(data):\n",
        "    STEP = 32\n",
        "    out_data = []\n",
        "    for i in tqdm(range(0, len(data), STEP)):\n",
        "        theslice = data[i: i + STEP]\n",
        "        questions_to_translate = map(lambda x: x['question'], theslice)\n",
        "        questions_to_translate = list(questions_to_translate)\n",
        "        back_translated = back_translate(questions_to_translate)\n",
        "\n",
        "\n",
        "        upper_range = i + STEP if (i + STEP < len(data)) else len(data)\n",
        "        for ii, jj in enumerate(range(i, upper_range)):\n",
        "            thedict = {key: value for key, value in data[jj].items()}\n",
        "            thedict['translated_question'] = back_translated[ii]\n",
        "            out_data.append(thedict)\n",
        "        \n",
        "        # TODO: RAJBIR: Remove the following line\n",
        "        if i > 500:\n",
        "            break\n",
        "    return out_data\n",
        "\n",
        "        \n",
        "\n",
        "data3 = backtranslate_questions_only(data2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVtXQjz7ggxR",
        "outputId": "4baaca6e-af35-4118-b018-897a36bb6d42"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 6/1563 [00:42<3:05:18,  7.14s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NewField: translated_intermediate_context\n",
        "- translated_intermediate_context: Translate the intermediate context, will sitll contain 11111..."
      ],
      "metadata": {
        "id": "UHwUrD6nob25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backtranslate_intermediate_question_only(data):\n",
        "    STEP = 8\n",
        "    out_data = []\n",
        "    for i in tqdm(range(0, len(data), STEP)):\n",
        "        theslice = data[i: i + STEP]\n",
        "        ctx_to_translate = map(lambda x: x['intermediate_context'], theslice)\n",
        "        ctx_to_translate = list(ctx_to_translate)\n",
        "        back_translated = back_translate(ctx_to_translate)\n",
        "\n",
        "        upper_range = i + STEP if (i + STEP < len(data)) else len(data)\n",
        "        for ii, jj in enumerate(range(i, upper_range)):\n",
        "            thedict = {key: value for key, value in data[jj].items()}\n",
        "            thedict['translated_intermediate_context'] = back_translated[ii]\n",
        "            out_data.append(thedict)\n",
        "        \n",
        "        # TODO: RAJBIR: remove these lines\n",
        "        if i > 15:\n",
        "            break\n",
        "\n",
        "    return out_data\n",
        "\n",
        "data4 = backtranslate_intermediate_question_only(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l8h1gurkmJy",
        "outputId": "ff10ed38-9c5a-4ca7-a8f3-762c816f6ee3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 2/84 [00:47<32:41, 23.92s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NewField: reconstructed_translated_ctx, new_answer_start\n",
        "- reconstructed_translated_ctx - the new context for final use after retranslation and reconstruction\n",
        "- new_answer_start - the start index of the answer has changed"
      ],
      "metadata": {
        "id": "TwkLISPq-yPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_start_end_index(context, replaced):\n",
        "    with open(\"save.txt\", \"a\") as f:\n",
        "        print(context, file=f)\n",
        "        print(replaced, file=f)\n",
        "\n",
        "    try:\n",
        "        start_ind = context.index(replaced)\n",
        "    except:\n",
        "        # Sometimes the replaced string is truncated by the\n",
        "        # translation, try again with half the string to see\n",
        "        # if there is a match\n",
        "        if len(replaced) < 4:\n",
        "            return -1, -1\n",
        "        try:\n",
        "            start_ind = context.index(replaced[:len(replaced) // 2])\n",
        "        except:\n",
        "            if len(replaced) < 8:\n",
        "                return -1, -1\n",
        "            try:\n",
        "                start_ind = context.index(replaced[len(replaced) // 4])\n",
        "            except:\n",
        "                return -1, -1\n",
        "\n",
        "    start_char = replaced[0]\n",
        "    end_ind = start_ind\n",
        "    while end_ind < len(context) and context[end_ind] == start_char:\n",
        "        end_ind += 1\n",
        "    return start_ind, end_ind\n",
        "\n",
        "def reconstruct_translated_question(data):\n",
        "    def reconstruct(thedict:dict)->dict:\n",
        "        out_dict = {k: v for k, v in thedict.items()}\n",
        "        trctx = thedict['translated_intermediate_context']\n",
        "        replaced = thedict['replaced_string']\n",
        "        stind, endind = get_start_end_index(trctx, replaced)\n",
        "        if stind == -1 or endind == -1:\n",
        "            out_dict['reconstructed_translated_ctx'] = thedict['context']\n",
        "            out_dict['new_answer_start'] = thedict['answer_start']\n",
        "        else:\n",
        "            origans = thedict['answer_text']\n",
        "            str1 = trctx[:stind]\n",
        "            str2 = trctx[endind:]\n",
        "            out_dict['reconstructed_translated_ctx'] = str1 + origans + str2\n",
        "            out_dict['new_answer_start'] = \\\n",
        "                out_dict['reconstructed_translated_ctx'].index(origans)\n",
        "        return out_dict\n",
        "    return list(map(reconstruct, data))\n",
        "\n",
        "data5 = reconstruct_translated_question(data4)"
      ],
      "metadata": {
        "id": "tH8Xxbq2-2Mi"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data5[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC8evtAw-k8U",
        "outputId": "a55cfe4e-e8be-45b6-dcec-b8334c5143ef"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer_start': 92,\n",
              "  'answer_text': 'a golden statue of the Virgin Mary',\n",
              "  'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              "  'id': 'deadcafe1c969af40a3248eb87a6d8c9c7c8d4ad',\n",
              "  'intermediate_context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is 1111111111111111111111111111111111. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              "  'new_answer_start': 100,\n",
              "  'orig_answer_len': 34,\n",
              "  'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "  'reconstructed_translated_ctx': 'Architecturally, the school has a Catholic character. Above the golden dome of the main building is a golden statue of the Virgin Mary. Immediately in front of the main building and in front of it, is a copper statue of Christ with arms erected with the legend \"Venite Ad Me Omnis\". Next to the main building is the basilica of the Sacred Heart. Immediately behind the basilica is the Cave, a Marian place of prayer and reflection. It is a replica of the cave in Lourdes, France where the Virgin Mary is deemed to have appeared to Saint Bernadette Soubirous in 1858.',\n",
              "  'replaced_string': '1111111111111111111111111111111111',\n",
              "  'translated_intermediate_context': 'Architecturally, the school has a Catholic character. Above the golden dome of the main building is 11111111111111111111111111111. Immediately in front of the main building and in front of it, is a copper statue of Christ with arms erected with the legend \"Venite Ad Me Omnis\". Next to the main building is the basilica of the Sacred Heart. Immediately behind the basilica is the Cave, a Marian place of prayer and reflection. It is a replica of the cave in Lourdes, France where the Virgin Mary is deemed to have appeared to Saint Bernadette Soubirous in 1858.',\n",
              "  'translated_question': 'What is above the main building of Notre Dame?'},\n",
              " {'answer_start': 675,\n",
              "  'answer_text': 'Buechner Prize for Preaching',\n",
              "  'context': 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.',\n",
              "  'id': 'deadcafe65cde452a73841a9aeb0cc3e844afce6',\n",
              "  'intermediate_context': 'The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a 1111111111111111111111111111.',\n",
              "  'new_answer_start': 715,\n",
              "  'orig_answer_len': 28,\n",
              "  'question': 'Which prize did Frederick Buechner create?',\n",
              "  'reconstructed_translated_ctx': 'The university is the principal seat of the Congregation of St. Croix (although it is not its official seat, which is located in Rome). Its main seminary, the Moreau seminary, is located on the campus opposite Lake St. Joseph of the main building. The former college, the oldest building on the campus and located near the shore of Lake St. Marie, houses the undergraduate seminarians. Priests and retired brothers reside in Fatima House (an old retirement centre), Santa Croix House, as well as Columba Hall near the Grotte. The university by the Moreau seminary has links with the theologian Frederick Buechner. Although not Catholic, Buechner has rented the writers of Our Lady and the Moreau seminary created a Buechner Prize for Preaching',\n",
              "  'replaced_string': '1111111111111111111111111111',\n",
              "  'translated_intermediate_context': 'The university is the principal seat of the Congregation of St. Croix (although it is not its official seat, which is located in Rome). Its main seminary, the Moreau seminary, is located on the campus opposite Lake St. Joseph of the main building. The former college, the oldest building on the campus and located near the shore of Lake St. Marie, houses the undergraduate seminarians. Priests and retired brothers reside in Fatima House (an old retirement centre), Santa Croix House, as well as Columba Hall near the Grotte. The university by the Moreau seminary has links with the theologian Frederick Buechner. Although not Catholic, Buechner has rented the writers of Our Lady and the Moreau seminary created a 11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111',\n",
              "  'translated_question': 'What award did Frederick Buechner create?'},\n",
              " {'answer_start': 46,\n",
              "  'answer_text': '1920',\n",
              "  'context': 'The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'id': 'deadcafe55aac6d971f74ee788b641f82ae0635c',\n",
              "  'intermediate_context': 'The College of Engineering was established in 1111, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'new_answer_start': 42,\n",
              "  'orig_answer_len': 4,\n",
              "  'question': 'In what year was the College of Engineering at Notre Dame formed?',\n",
              "  'reconstructed_translated_ctx': 'The College of Engineering was created in 1920, however, the first courses in civil and mechanical engineering had been part of the College of Science since the 1870s. Today, the College, housed in the Fitzpatrick, Cushing, and Stinson-Remick Engineering Halls, comprises five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer science and engineering, and electrical engineering – with eight B.S. diplomas offered. In addition, the College offers five-year dual degree programs with the Colleges of Arts and Letters and Business assigning additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'replaced_string': '1111',\n",
              "  'translated_intermediate_context': 'The College of Engineering was created in 1111, however, the first courses in civil and mechanical engineering had been part of the College of Science since the 1870s. Today, the College, housed in the Fitzpatrick, Cushing, and Stinson-Remick Engineering Halls, comprises five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer science and engineering, and electrical engineering – with eight B.S. diplomas offered. In addition, the College offers five-year dual degree programs with the Colleges of Arts and Letters and Business assigning additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'translated_question': 'In what year was the College of Engineering of Notre Dame formed?'},\n",
              " {'answer_start': 271,\n",
              "  'answer_text': 'five',\n",
              "  'context': 'The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'id': 'deadcafe0e413afa4f65444fa504e75fe6a4cfaa',\n",
              "  'intermediate_context': 'The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes 1111 departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'new_answer_start': 271,\n",
              "  'orig_answer_len': 4,\n",
              "  'question': 'How many departments are within the Stinson-Remick Hall of Engineering?',\n",
              "  'reconstructed_translated_ctx': 'The College of Engineering was established in 1920, however, the first courses in civil and mechanical engineering were part of the College of Science since the 1870s. Today, the College, housed in the Fitzpatrick, Cushing and Stinson-Remick Engineering Halls, comprises five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer and engineering, and electrical engineering – with eight B.S. diplomas offered. In addition, the College offers two-year programs with the Colleges of Arts and Letters and Business granting additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'replaced_string': '1111',\n",
              "  'translated_intermediate_context': 'The College of Engineering was established in 1920, however, the first courses in civil and mechanical engineering were part of the College of Science since the 1870s. Today, the College, housed in the Fitzpatrick, Cushing and Stinson-Remick Engineering Halls, comprises 1111 departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer and engineering, and electrical engineering – with eight B.S. diplomas offered. In addition, the College offers two-year programs with the Colleges of Arts and Letters and Business granting additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'translated_question': 'How many departments are there in the engineering room Stinson-Remick?'},\n",
              " {'answer_start': 155,\n",
              "  'answer_text': 'the 1870s',\n",
              "  'context': 'The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'id': 'deadcafe7df04a5b7810494cb11fb97c969f8658',\n",
              "  'intermediate_context': 'The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since 111111111. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'new_answer_start': 162,\n",
              "  'orig_answer_len': 9,\n",
              "  'question': 'The College of Science began to offer civil engineering courses beginning at what time at Notre Dame?',\n",
              "  'reconstructed_translated_ctx': 'The College of Engineering was established in 1920, however, the first courses in civil and mechanical engineering have been part of the College of Science since the 1870s. Today, the College, housed in the Fitzpatrick, Cushing and Stinson-Remick Engineering Halls, comprises five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. In addition, the College offers two-degree five-year programs with the Colleges of Arts and Letters and Business granting additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'replaced_string': '111111111',\n",
              "  'translated_intermediate_context': 'The College of Engineering was established in 1920, however, the first courses in civil and mechanical engineering have been part of the College of Science since 1111111. Today, the College, housed in the Fitzpatrick, Cushing and Stinson-Remick Engineering Halls, comprises five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil and geological engineering, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. In addition, the College offers two-degree five-year programs with the Colleges of Arts and Letters and Business granting additional B.A. and Master of Business Administration (MBA) degrees, respectively.',\n",
              "  'translated_question': 'The College of Sciences began offering civil engineering courses at what time in Notre Dame?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Memory"
      ],
      "metadata": {
        "id": "SXTuWREMyPBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gc\n",
        "result = []\n",
        "\n",
        "for tracked_object in gc.get_objects():\n",
        "    if torch.is_tensor(tracked_object):\n",
        "        shape = tracked_object.shape\n",
        "        result.append({\n",
        "            'name': type(tracked_object).__name__,\n",
        "            '1d': len(shape)==1,\n",
        "            '2d': len(shape)==2,\n",
        "            'nrows': shape[0],\n",
        "            'ncols': shape[1] if (len(shape) > 1) else None,\n",
        "            'gpu': tracked_object.is_cuda,\n",
        "            'pinned': tracked_object.is_pinned()\n",
        "        })\n",
        "        \n",
        "d = pd.DataFrame(result)\n",
        "d.groupby('name')['gpu', 'pinned', '1d', '2d'].sum()"
      ],
      "metadata": {
        "id": "0xnlS8mhpx4G",
        "outputId": "22517cd2-bbeb-4e7a-8e27-132881ea1103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
            "__main__:19: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5fcb2e5e-e411-4b32-8639-52fc9a463ba7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gpu</th>\n",
              "      <th>pinned</th>\n",
              "      <th>1d</th>\n",
              "      <th>2d</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Parameter</th>\n",
              "      <td>510</td>\n",
              "      <td>0</td>\n",
              "      <td>312</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tensor</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fcb2e5e-e411-4b32-8639-52fc9a463ba7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fcb2e5e-e411-4b32-8639-52fc9a463ba7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fcb2e5e-e411-4b32-8639-52fc9a463ba7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           gpu  pinned   1d   2d\n",
              "name                            \n",
              "Parameter  510       0  312  198\n",
              "Tensor       2       0    0    2"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mSLsuuxNr611"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3snbqy-oxR5N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}