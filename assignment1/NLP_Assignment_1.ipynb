{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFakUSUEoJEzrkTRXE2TYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattacharjee/mtu-nlp-assignment/blob/main/assignment1/NLP_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-DAX9VLZlw3"
      },
      "source": [
        "import requests\n",
        "def get_train_test_files():\n",
        "    TRAIN_FILE = 'https://raw.githubusercontent.com/bhattacharjee/mtu-nlp-assignment/main/assignment1/Assessment1_Toxic_Train.csv'\n",
        "    TEST_FILE = 'https://raw.githubusercontent.com/bhattacharjee/mtu-nlp-assignment/main/assignment1/Assessment1_Toxic_Test_For_Evaluation.csv'\n",
        "    TRAIN_FILE_LOCAL = 'Assessment1_Toxic_Train.csv'\n",
        "    TEST_FILE_LOCAL = 'Assessment1_Toxic_Test.csv'\n",
        "\n",
        "    def download(url, localfile):\n",
        "        with open(localfile, 'wb') as f:\n",
        "            r = requests.get(url, allow_redirects=True)\n",
        "            f.write(r.content)\n",
        "\n",
        "    download(TRAIN_FILE, TRAIN_FILE_LOCAL)\n",
        "    download(TEST_FILE, TEST_FILE_LOCAL)\n",
        "\n",
        "    return TRAIN_FILE_LOCAL, TEST_FILE_LOCAL\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERvBOEn0wss6",
        "outputId": "8a375001-944e-4c7b-b928-611bb004cb26"
      },
      "source": [
        "!pip install spacy nltk huggingface -q\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.5.30)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v6ohiY0s5N1"
      },
      "source": [
        "import pandas as pd\n",
        "def get_train_test_df():\n",
        "    train_csv, test_csv = get_train_test_files()\n",
        "\n",
        "    train_df = pd.read_csv(train_csv)\n",
        "    test_df = pd.read_csv(test_csv)\n",
        "\n",
        "    return train_df, test_df"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ljpCC2uFLn"
      },
      "source": [
        "train_df, test_df = get_train_test_df()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVfYulLnuGVJ"
      },
      "source": [
        "import re\n",
        "def remove_roles(line:str)->str:\n",
        "    # Remove texts like @USER, @MODERATOR etc\n",
        "    pat = re.compile(u'\\@[A-Za-z]+')\n",
        "    return re.sub(pat, '', line)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nU-BO8guUcM"
      },
      "source": [
        "import re\n",
        "def remove_emojis(line:str)->str:\n",
        "    pat = re.compile(\n",
        "        \"[\"\n",
        "            u\"\\U0001F600-\\U0001F64F\"\n",
        "            u\"\\U0001F300-\\U0001F5FF\"\n",
        "            u\"\\U0001F680-\\U0001F6FF\"\n",
        "            u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        \"]\", flags=re.UNICODE)\n",
        "    return re.sub(pat, '', line)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6JFm16r7M3E"
      },
      "source": [
        "def to_lower(line:str)->str:\n",
        "    return line.lower()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_TxMNrC7doY",
        "outputId": "f5fc22e9-7da3-4247-cb38-f29dda930757"
      },
      "source": [
        "print(train_df.columns)\n",
        "print(train_df['comment_text'])\n",
        "train_df['comment_text'] = train_df['comment_text']                         \\\n",
        "                            .map(to_lower)                                  \\\n",
        "                            .map(remove_emojis)                             \\\n",
        "                            .map(remove_roles)\n",
        "\n",
        "test_df['comment_text'] = test_df['comment_text']                           \\\n",
        "                            .map(to_lower)                                  \\\n",
        "                            .map(remove_emojis)                             \\\n",
        "                            .map(remove_roles)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['comment_text', 'Sub1_Toxic', 'Sub2_Engaging', 'Sub3_FactClaiming'], dtype='object')\n",
            "0       Gestern bei Illner, Montag bei @MODERATOR ...i...\n",
            "1       Mein Gott der war erst gestern bei Illner. Die...\n",
            "2       @USER Die CDU lässt das so wie so nicht zu . S...\n",
            "3       Bei meiner beschissenen Rente als 2x Geschiede...\n",
            "4       Wer 40 Jahre zum Mindestlohn arbeiten muß, erh...\n",
            "                              ...                        \n",
            "3189    Hier mal eine Info. Flüchtlinge werden 10 km v...\n",
            "3190    @USER.aha .Mal abwarten kommt bei uns auch .Fi...\n",
            "3191                                     @USER .So ist es\n",
            "3192                                 @USER .Die warten da\n",
            "3193    @USER .Das bekommen die gesagt wie sich verhal...\n",
            "Name: comment_text, Length: 3194, dtype: object\n",
            "                                         comment_text\n",
            "0   ziemlich traurig diese kommentare zu lesen. ih...\n",
            "1   sag ich doch, wir befeuern den klimawandel. ra...\n",
            "2   dummerweise haben wir in der eu und in der usa...\n",
            "3   \"so lange gewinnmaximierung vorrang hat, wird ...\n",
            "4   sollte es dann doch einen klimawandel geben, d...\n",
            "5    ja o.k aber nicht mit so schwachsinnigen dars...\n",
            "6    seltsamerweise steigen die temperaturen mit d...\n",
            "7    aus sicht der grã¼nen fraktion kurz ã¼berschl...\n",
            "8   wenn die industrie angeblich so extrem viel tu...\n",
            "9                  die luftqualitã¤t ist nicht besser\n",
            "10  schublade auf, schublade zu. zu mehr denkleist...\n",
            "11                  schon mal was von physik gehã¶rt?\n",
            "12   geh wieder pennen...dein gesã¼lze interessier...\n",
            "13  wenn ich einen konjunktiv verwende hat das ein...\n",
            "14                          nach mir die sintflut â˜º\n",
            "15                                staatsfernsehen ! !\n",
            "16   oh weh das mã¶chten wir uns garnicht vorstellen.\n",
            "17  aber eure generation waren die schlimmsten ver...\n",
            "18  eine ernsthafte diskussion ist doch vã¶llig ã¼...\n",
            "19  fã¼r deutsche/einzahler gibt es wieder nix ! a...\n",
            "20  \" 675 milliarden!\" das ist dein denkfehler. au...\n",
            "21   geld ist genug da. oder mit volker pispers wo...\n",
            "22   wir bezahlen auch nur mit unserem vertrauen. ...\n",
            "23  war schon thema bei illner. kã¶nnt ihr euch ni...\n",
            "24  soll er keine rente erhalten? ãœbrigens bekomm...\n",
            "25  wie doof muãÿ man eigentlich sein,um diesen lã...\n",
            "26  passt zum thema friedmann gestern wo die cdu p...\n",
            "27  diese ankã¼ndigungen werden immer vor wahlen g...\n",
            "28                              ...ohne kommentar!!!!\n",
            "29  wer zahlt den die steuern, ....das ist das gel...\n",
            "30  die \"rentenreform\" der spd ist ein schlechter ...\n",
            "31  die \"rentenreform\" der spd ist ein schlechter ...\n",
            "32  wie wã¤re es dann mit einem (bedingungslosen) ...\n",
            "33  und jede form des einkommens wird ab einer bes...\n",
            "34   nein, bei der finanzierung liegst du komplett...\n",
            "35   artikel 14 gg ist sicherlich bekannt. wobei a...\n",
            "36  3) unser geldsystem (euro, eurokrise, alternat...\n",
            "37  \"das geld dafã¼r kann man doch einfach drucken...\n",
            "38  zu dem verweise ich gerne auf meine facebookse...\n",
            "39  die idee einer grundrente kommt von der linksp...\n",
            "40  sehr gut analysiert - bin ich vollkommen konfo...\n",
            "41   noch mehr bã¼rokratie? gleiches geld fã¼r all...\n",
            "42         alle ausreisepflichtige flã¼chtlinge raus.\n",
            "43   doch wurde und wird was verteilt , die diã¤te...\n",
            "44                                       wieso schule\n",
            "45  es ist fatal die einen hilfesuchenden menschen...\n",
            "46  ich bin ganz klar fã¼r die besteuerung. nur mã...\n",
            "47  also eine gleiche rente fã¼r alle? wie wã¤re e...\n",
            "48  , warum wã¤hlt man eine partei, die den tod vo...\n",
            "49  wie wã¤re es mit der steuerpolitik der partei ...\n",
            "50  gestern bei illner, montag bei  ...ist das nic...\n",
            "51  mein gott der war erst gestern bei illner. die...\n",
            "52   die cdu lã¤sst das so wie so nicht zu . sagen...\n",
            "53  bei meiner beschissenen rente als 2x geschiede...\n",
            "54  wer 40 jahre zum mindestlohn arbeiten muãÿ, er...\n",
            "55  wenn ich immer lese \"das muss die jã¼ngere gen...\n",
            "56  das machen wir doch. und deswegen zerstã¶ren w...\n",
            "57  die jã¼ngere generation bekommt so viel kinder...\n",
            "58                       keine sorge, sie wussten es.\n",
            "59  gute kritik, doch wir brauchen nicht nur 13 eu...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "s8YSZZ4vxTk5",
        "outputId": "ee8700fa-41c8-44ba-8a02-aa4ada65f0c3"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "def is_punct_only(token:str)->bool:\n",
        "    for c in list(token):\n",
        "        if c not in string.punctuation:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def do_nlp_cleaning(line:str):\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(line)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words(\"german\"))\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "    # TODO: Remove punctuations\n",
        "    tokens = [w for w in tokens if not is_punct_only(w)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sentence = \" Gestern bei Illner, Montag bei  ...ist das nic...\"\n",
        "do_nlp_cleaning(sentence)\n",
        "\n",
        "\"\"\"\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "\n",
        "sentence = \"I'm a dog and it's great! You're cool and Sandy's book is big. Don't tell her, you'll regret it! 'Hey', she'll say!\"\n",
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer\n",
        "for x in nlp.tokenizer(sentence):\n",
        "    print(x)\n",
        "\"\"\""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['Gestern', 'Illner', ',', 'Montag', '...', 'nic', '...']\n",
            "['Gestern', 'Illner', 'Montag', 'nic']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom spacy.tokenizer import Tokenizer\\nfrom spacy.lang.en import English\\n\\nsentence = \"I\\'m a dog and it\\'s great! You\\'re cool and Sandy\\'s book is big. Don\\'t tell her, you\\'ll regret it! \\'Hey\\', she\\'ll say!\"\\nnlp = English()\\ntokenizer = nlp.tokenizer\\nfor x in nlp.tokenizer(sentence):\\n    print(x)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6HysGzPvUsJ",
        "outputId": "a7c03279-7108-409f-8cd4-0b65e11b7b39"
      },
      "source": [
        "train_df['comment_text'].map(remove_roles).map(remove_emojis)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Gestern bei Illner, Montag bei  ...ist das nic...\n",
              "1       Mein Gott der war erst gestern bei Illner. Die...\n",
              "2        Die CDU lässt das so wie so nicht zu . Sagen ...\n",
              "3       Bei meiner beschissenen Rente als 2x Geschiede...\n",
              "4       Wer 40 Jahre zum Mindestlohn arbeiten muß, erh...\n",
              "                              ...                        \n",
              "3189    Hier mal eine Info. Flüchtlinge werden 10 km v...\n",
              "3190    .aha .Mal abwarten kommt bei uns auch .Firmen ...\n",
              "3191                                           .So ist es\n",
              "3192                                       .Die warten da\n",
              "3193     .Das bekommen die gesagt wie sich verhalten s...\n",
              "Name: comment_text, Length: 3194, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4omBVP_7wBM2"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}